{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d171cb-dd71-4251-a817-81e0536669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.functional import relu\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "import torch\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from PIL import Image, ImageOps\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc\n",
    "from torchvision.models.video import r3d_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf8aa22-ff0a-49a2-b0ff-a32d88552f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet import ResNet3D\n",
    "\n",
    "# #https://github.com/kbressem/faimed3d/blob/main/faimed3d/models/resnet.py#L257\n",
    "\n",
    "# # Create ResNet18 model\n",
    "# model = ResNet3D(layers=18, num_classes=3)\n",
    "\n",
    "# # (Optional) Load Pretrained Weights\n",
    "# pretrained_path = \"/path/to/pretrained_weights.pth\"  # Change the path according to your pretrained weights file\n",
    "# if os.path.exists(pretrained_path):\n",
    "#     state_dict = torch.load(pretrained_path, map_location=torch.device('cpu'))  # Load the state_dict\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     print(\"Pretrained weights loaded successfully.\")\n",
    "# else:\n",
    "#     print(\"No pretrained weights found, initializing model with random weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8c631d-6511-420f-a396-11fc32115ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('y')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2346fd87-1873-4ac9-a77e-36fda0b282b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbdominalDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.label = self.data_frame['target']\n",
    "\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir,\n",
    "                                self.data_frame.iloc[idx, -2])\n",
    "\n",
    "        image = np.load(img_name)\n",
    "        label = self.label[idx]\n",
    "\n",
    "        image = image.astype(np.float32)\n",
    "        label = label.astype(np.float32)\n",
    "\n",
    "        resized_image = F.interpolate(torch.tensor(image).unsqueeze(0).unsqueeze(0), size=(128, 128, 128), mode='trilinear', align_corners=False).squeeze().numpy()\n",
    "\n",
    "        # Normalize the image\n",
    "        min_image = np.min(resized_image)\n",
    "        max_image = np.max(resized_image)\n",
    "        resized_image = (resized_image - min_image) / (max_image - min_image + 1e-4)\n",
    "\n",
    "        # Convert to tensors\n",
    "        image = torch.tensor(resized_image).float().unsqueeze(0)\n",
    "        label = torch.tensor(label).long()\n",
    "\n",
    "        sample = {'x': image, 'y': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff46cd7-ae9c-4f94-aabc-c2c261f6a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer,  loss_fn, num_epochs = 10, verbose = False):\n",
    "    acc_dict = {'train':[],'validate':[]}\n",
    "    loss_dict = {'train':[],'validate':[]}\n",
    "    best_acc = 0\n",
    "    phases = ['train','validate']\n",
    "    since = time.time()\n",
    "    for i in range(num_epochs):\n",
    "        print('Epoch: {}/{}'.format(i, num_epochs-1))\n",
    "        print('-'*10)\n",
    "        for p in phases:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if p == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for data in dataloader[p]:\n",
    "                optimizer.zero_grad()            \n",
    "                image = data['x'].to(device)\n",
    "                label = data['y'].to(device)\n",
    "                output = model(image)\n",
    "                loss = loss_fn(output, label)\n",
    "                _, preds = torch.max(output, dim = 1)\n",
    "                num_imgs = image.size()[0]\n",
    "                running_correct += torch.sum(preds ==label).item()\n",
    "                running_loss += loss.item()*num_imgs\n",
    "                running_total += num_imgs\n",
    "                if p== 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            epoch_acc = float(running_correct/running_total)\n",
    "            epoch_loss = float(running_loss/running_total)\n",
    "            if verbose or (i%10 == 0):\n",
    "                print('Phase:{}, epoch loss: {:.4f} Acc: {:.4f}'.format(p, epoch_loss, epoch_acc))\n",
    "\n",
    "            acc_dict[p].append(epoch_acc)\n",
    "            loss_dict[p].append(epoch_loss)\n",
    "            if p == 'validate':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = model.state_dict()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, acc_dict, loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b5232-e8d7-4899-be31-35b19f7b6d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/2\n",
      "----------\n",
      "Phase:train, epoch loss: 0.4455 Acc: 0.8642\n",
      "Phase:validate, epoch loss: 0.4375 Acc: 0.8787\n",
      "Epoch: 1/2\n",
      "----------\n",
      "Phase:train, epoch loss: 0.3472 Acc: 0.9016\n",
      "Phase:validate, epoch loss: 0.3721 Acc: 0.8787\n",
      "Epoch: 2/2\n",
      "----------\n",
      "Phase:train, epoch loss: 0.3271 Acc: 0.9024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bs = 2\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory, '..', 'data')\n",
    "\n",
    "dataset = {'train': AbdominalDataset(os.path.join(data_directory, 'train.csv'),'/vast/amr10211/deep_learning_final_project/images_preprocessed/'), \n",
    "           'validate': AbdominalDataset(os.path.join(data_directory, 'val.csv'),'/vast/amr10211/deep_learning_final_project/images_preprocessed/'), \n",
    "           'test': AbdominalDataset(os.path.join(data_directory, 'test.csv'),'/vast/amr10211/deep_learning_final_project/images_preprocessed/')}\n",
    "dataloader = {x: DataLoader(dataset[x], batch_size=bs,\n",
    "                        shuffle=True, num_workers=0) for x in ['train', 'validate']}\n",
    "\n",
    "model = r3d_18(weights=True)\n",
    "model.stem = nn.Conv3d(1, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model, acc_dict, loss_dict = train_model(model, dataloader, optimizer, loss_fn=criterion, num_epochs = 3,  verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23858e7-0a94-43c5-9624-657c4d14a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(loss_dict['train'])),loss_dict['train'], label = 'Training Loss per Epoch')\n",
    "plt.plot(range(0,len(loss_dict['validate'])),loss_dict['validate'],  label = 'Validation Loss per Epoch')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a7105-8458-4b30-b06e-5ca368baf680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    total_f1 = np.zeros(num_classes)\n",
    "    total_auc = np.zeros(num_classes)\n",
    "    total_samples = 0\n",
    "    \n",
    "    all_labels = np.array([])\n",
    "    all_preds = np.array([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            image = data['x'].to(device)\n",
    "            labels = data['y'].to(device)\n",
    "            outputs = model(image)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_labels = np.concatenate((all_labels, labels.cpu().numpy()), axis=0)\n",
    "            all_preds = np.concatenate((all_preds, preds.cpu().numpy()), axis=0)\n",
    "            \n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    # Calculate F1 score and AUC curve for each class\n",
    "    for cls in range(num_classes):\n",
    "        cls_labels = (all_labels == cls).astype(int)\n",
    "        cls_preds = (all_preds == cls).astype(int)\n",
    "        \n",
    "        total_f1[cls] = f1_score(cls_labels, cls_preds)\n",
    "        fpr, tpr, _ = roc_curve(cls_labels, cls_preds)\n",
    "        total_auc[cls] = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % total_auc[cls])\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve - Class {}'.format(cls))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    macro_f1 = np.mean(total_f1)\n",
    "    \n",
    "    return macro_f1, total_auc\n",
    "\n",
    "\n",
    "\n",
    "eval_dataloader = {x: DataLoader(dataset[x], batch_size=bs,\n",
    "                        shuffle=False, num_workers=0) for x in ['validate','test']}\n",
    "\n",
    "#Calculate Dice:\n",
    "\n",
    "val_macro_f1, val_total_auc = evaluate_model(model, eval_dataloader['validate'], device, 3)\n",
    "print(\"Validation Macro F1:\", val_macro_f1)\n",
    "print(\"Validation AUC:\", val_total_auc)\n",
    "\n",
    "test_macro_f1, test_total_auc = evaluate_model(model, eval_dataloader['test'], device, 3)\n",
    "print(\"Test Macro F1:\", test_macro_f1)\n",
    "print(\"Test AUC:\", test_total_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae5597-1f7b-4a7c-993a-7a96579b6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'classification_model_resnet18_uncropped_1.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
