{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d171cb-dd71-4251-a817-81e0536669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.functional import relu\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "import torch\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from PIL import Image, ImageOps\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix\n",
    "from torchvision.models.video import r3d_18\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomVerticalFlip, RandomRotation\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8c631d-6511-420f-a396-11fc32115ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('y')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7868f9-8bda-4dd8-a132-dcec71c1a837",
   "metadata": {},
   "source": [
    "## Dataset & Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2346fd87-1873-4ac9-a77e-36fda0b282b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation3D(object):\n",
    "    def __init__(self, degrees):\n",
    "        self.degrees = degrees\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (numpy.ndarray): Input 3D image numpy array.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Randomly rotated image.\n",
    "        \"\"\"\n",
    "        # Randomly select the rotation angle\n",
    "        angle = np.random.uniform(-self.degrees, self.degrees)\n",
    "\n",
    "        # Perform rotation\n",
    "        rotated_img = np.array([np.rot90(slice, k=int(angle / 90)) for slice in img])\n",
    "\n",
    "        return rotated_img\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    RandomRotation3D(degrees=5)\n",
    "])\n",
    "\n",
    "\n",
    "class AbdominalDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.label = self.data_frame['target']\n",
    "\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir,\n",
    "                                self.data_frame.iloc[idx, -2])\n",
    "\n",
    "        image = np.load(img_name)\n",
    "        label = self.label[idx]\n",
    "\n",
    "        image = image.astype(np.float32)\n",
    "        label = label.astype(np.float32)\n",
    "\n",
    "        resized_image = F.interpolate(torch.tensor(image).unsqueeze(0).unsqueeze(0), size=(128, 128, 128), mode='trilinear', align_corners=False).squeeze().numpy()\n",
    "\n",
    "        # Select only the last 64 slices: \n",
    "        resized_image = resized_image[-64:, :, :]\n",
    "\n",
    "        if self.transform:\n",
    "            resized_image = self.transform(resized_image)\n",
    "            \n",
    "        # Normalize the image\n",
    "        min_image = np.min(resized_image)\n",
    "        max_image = np.max(resized_image)\n",
    "        resized_image = (resized_image - min_image) / (max_image - min_image + 1e-4)\n",
    "\n",
    "    \n",
    "        # Convert to tensors\n",
    "        image = torch.tensor(resized_image).float().unsqueeze(0)\n",
    "        label = torch.tensor(label).long()\n",
    "\n",
    "        sample = {'x': image, 'y': label}\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff46cd7-ae9c-4f94-aabc-c2c261f6a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_fn, num_epochs=10, verbose=False):\n",
    "    acc_dict = {'train': [], 'validate': []}\n",
    "    loss_dict = {'train': [], 'validate': []}\n",
    "    best_loss = 1e30\n",
    "    phases = ['train', 'validate']\n",
    "    since = time.time()\n",
    "    for i in range(num_epochs):\n",
    "        print('Epoch: {}/{}'.format(i, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for p in phases:\n",
    "            running_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            if p == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            for data in dataloader[p]:\n",
    "                optimizer.zero_grad()\n",
    "                image, label = data['x'], data['y']\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                outputs = model(image)\n",
    "                loss = loss_fn(outputs.squeeze(),  label.float())  # Squeeze the output to remove the extra dimension\n",
    "\n",
    "                if p == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                preds = torch.round(torch.sigmoid(outputs))  # Round the sigmoid output to get 0 or 1\n",
    "                num_imgs = image.size()[0]\n",
    "                running_correct += torch.sum(preds == label).item()\n",
    "                running_loss += loss.item() * num_imgs\n",
    "                running_total += num_imgs\n",
    "\n",
    "            epoch_acc = float(running_correct / running_total)\n",
    "            epoch_loss = float(running_loss / running_total)\n",
    "            if verbose or (i % 10 == 0):\n",
    "                print('Phase:{}, epoch loss: {:.4f} Acc: {:.4f}'.format(p, epoch_loss, epoch_acc))\n",
    "\n",
    "            acc_dict[p].append(epoch_acc)\n",
    "            loss_dict[p].append(epoch_loss)\n",
    "            if p == 'validate':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = deepcopy(model.state_dict())\n",
    "\n",
    "        # scheduler.step()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Calculate F1 score for the validation set\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader['validate']:\n",
    "            optimizer.zero_grad()\n",
    "            image, label = data['x'], data['y']\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(image)\n",
    "            preds = torch.round(torch.sigmoid(outputs))  # Round the sigmoid output to get 0 or 1\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(label.cpu().numpy())\n",
    "            \n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "\n",
    "    print('Best F1: {:4f}'.format(val_f1))\n",
    "\n",
    "    return model, acc_dict, loss_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd636267-91a0-4e92-9a90-0098ec095c23",
   "metadata": {},
   "source": [
    "## ResNet18-3D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6978f953-bda2-4806-8d00-f14b3711b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_3D(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(ResNet18_3D, self).__init__()\n",
    "        self.resnet18_3d = r3d_18(weights='DEFAULT')\n",
    "\n",
    "        # Modify stem layer to accept single-channel input\n",
    "        self.resnet18_3d.stem = nn.Conv3d(1, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
    "        \n",
    "        # Change the last fully connected layer\n",
    "        self.resnet18_3d.fc = nn.Linear(self.resnet18_3d.fc.in_features, 1)\n",
    "        \n",
    "        # Add Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Add Batch Normalization\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.BatchNorm3d(512)\n",
    "        ])\n",
    "        \n",
    "        # Adaptive average pooling\n",
    "        self.adaptive_avg_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        \n",
    "        # Flatten\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18_3d.stem(x)\n",
    "        x = self.batch_norms[0](x)\n",
    "        x = self.resnet18_3d.layer1(x)\n",
    "        x = self.batch_norms[1](x)\n",
    "        x = self.resnet18_3d.layer2(x)\n",
    "        x = self.batch_norms[2](x)\n",
    "        x = self.resnet18_3d.layer3(x)\n",
    "        x = self.batch_norms[3](x)\n",
    "        x = self.resnet18_3d.layer4(x)\n",
    "        x = self.batch_norms[4](x)\n",
    "        x = self.adaptive_avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.resnet18_3d.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7c3c91-529d-4214-a53f-9deb41b3dd44",
   "metadata": {},
   "source": [
    "## Train Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24373417-f8fe-4a46-8aff-55ab2b8654e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/9\n",
      "----------\n",
      "Phase:train, epoch loss: 1.2473 Acc: 4.1300\n",
      "Phase:validate, epoch loss: 1.2995 Acc: 3.3191\n",
      "Epoch: 1/9\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "bs = 8\n",
    "lr = 0.0001\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "data_directory = os.path.join(current_directory, '..', 'data')\n",
    "\n",
    "model = ResNet18_3D().to(device)\n",
    "\n",
    "pos_weight = torch.tensor(10.0).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight = pos_weight, reduction='mean')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "dataset = {'train': AbdominalDataset(os.path.join(data_directory, 'train_binary.csv'),'/vast/amr10211/deep_learning_final_project/images_preprocessed/', train_transform), \n",
    "           'validate': AbdominalDataset(os.path.join(data_directory, 'val_binary.csv'),'/vast/amr10211/deep_learning_final_project/images_preprocessed/'),\n",
    "           'test': AbdominalDataset(os.path.join(data_directory, 'test_binary.csv'),'/vast/amr10211/deep_learning_final_project/images_preprocessed/')}\n",
    "\n",
    "dataloader = {x: DataLoader(dataset[x], batch_size=bs,\n",
    "                        shuffle=True) for x in ['train', 'validate']}\n",
    "\n",
    "model, acc_dict, loss_dict = train_model(model, dataloader, optimizer, loss_fn=criterion, num_epochs=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d839d4f-16ab-4293-b7f9-8e3e672316ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'classification_model_resnet18_binary_0_9_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e425d-eedb-495e-9528-f82e9f4585a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('acc_dict_resnet18_binary_0_9_3.pickle', 'wb') as handle:\n",
    "    pickle.dump(acc_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8cc27-1cf1-4c1d-8c0e-d7f6cc32fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('loss_dict_resnet18_binary_0_9_3.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f51455-6edb-4126-a9a7-e3effcc139a7",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6321a-7010-4a5b-b28a-c04ffd0cf586",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightorch.load(model.state_dict(), 'classification_model_resnet18_binary_0_9_3.pth')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749134f4-db78-472e-8d70-a83880f7dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_samples = 0\n",
    "    \n",
    "    all_labels = np.array([])\n",
    "    all_probs = np.array([])  # To store predicted probabilities\n",
    "    all_preds = np.array([])  # To store predicted class labels\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            image = data['x'].to(device)\n",
    "            labels = data['y'].to(device)\n",
    "            outputs = model(image)\n",
    "            probs = torch.sigmoid(outputs).squeeze(1)\n",
    "            preds = torch.round(probs) \n",
    "            \n",
    "            all_labels = np.concatenate((all_labels, labels.cpu().numpy()), axis=0)\n",
    "            all_probs = np.concatenate((all_probs, probs.cpu().numpy()), axis=0)\n",
    "            all_preds = np.concatenate((all_preds, preds.cpu().numpy()), axis=0)\n",
    "            \n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    \n",
    "    # Calculate FNR and FPR\n",
    "    fnr = fn / (fn + tp)\n",
    "    fpr = fp / (tn + fp)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    fprs, tprs, _ = roc_curve(all_labels, all_probs)\n",
    "    auc_score = auc(fprs, tprs)\n",
    "    \n",
    "    # Calculate AUPRC score\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "    auprc_score = average_precision_score(all_labels, all_probs)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    lw = 2\n",
    "    plt.plot(fprs, tprs, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Plot Precision-Recall curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve (AUPRC = %0.2f)' % auprc_score)\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "    return f1, auc_score, auprc_score, fnr, fpr\n",
    "\n",
    "eval_dataloader = {x: DataLoader(dataset[x], batch_size=bs,\n",
    "                        shuffle=False, num_workers=0) for x in ['test']}\n",
    "\n",
    "test_f1, test_auc, test_auprc, test_fnr, test_fpr = evaluate_model(model, eval_dataloader['test'], device)\n",
    "print(\"Test F1:\", test_f1)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(\"Test AUPRC:\", test_auprc)\n",
    "print(\"Test FNR:\", test_fnr)\n",
    "print(\"Test FPR:\", test_fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17b7b6-976b-4194-9e24-b917e12efaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c4679-70ad-4766-83fc-32fab20f2dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd202213-465b-4849-9810-7a60204ae25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa6677-775a-490d-a855-5bc9eabaa6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddfc0b-8572-4739-b92d-70e41abcf83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
